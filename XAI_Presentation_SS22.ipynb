{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "192827cb",
   "metadata": {},
   "source": [
    "### Library used: \n",
    "Alibi is an open source Python library aimed at machine learning model inspection and interpretation.\n",
    "### Input data\n",
    "In this dataset, each entry represents a person who takes a credit by a bank. <br>\n",
    "Each person is classified as good or bad credit risks according to the set of attributes.<br>\n",
    "Length: 1000 entries<br>\n",
    "The column names are:<br>\n",
    "1. Age (numeric)<br>\n",
    "2. Sex (text: male, female)<br>\n",
    "3. Job (numeric: 0 - unskilled and non-resident, 1 - unskilled and resident, 2 - skilled, 3 - highly skilled)<br>\n",
    "4. Housing (text: own, rent, or free)<br>\n",
    "5. Saving accounts (text - little, moderate, quite rich, rich)<br>\n",
    "6. Checking account (numeric)<br>\n",
    "7. Credit amount (numeric)<br>\n",
    "8. Duration (numeric, in month)<br>\n",
    "9. Purpose (text: car, furniture/equipment, radio/TV, domestic appliances, repairs, education, business, vacation/others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d028d382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: alibi in c:\\users\\acer\\anaconda3\\lib\\site-packages (0.6.5)\n",
      "Requirement already satisfied: dill<0.4.0,>=0.3.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from alibi) (0.3.4)\n",
      "Requirement already satisfied: pandas<2.0.0,>=0.23.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from alibi) (1.2.4)\n",
      "Requirement already satisfied: Pillow<10.0,>=5.4.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from alibi) (8.2.0)\n",
      "Requirement already satisfied: scikit-image!=0.17.1,<0.20,>=0.14.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from alibi) (0.18.1)\n",
      "Requirement already satisfied: tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from alibi) (2.7.0)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from alibi) (3.3.4)\n",
      "Requirement already satisfied: scikit-learn<1.1.0,>=0.20.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from alibi) (0.24.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.28.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from alibi) (4.59.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\acer\\appdata\\roaming\\python\\python38\\site-packages (from alibi) (3.10.0.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.7.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from alibi) (4.18.0)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.1.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from alibi) (1.6.2)\n",
      "Requirement already satisfied: spacy[lookups]<4.0.0,>=2.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from alibi) (3.3.0)\n",
      "Requirement already satisfied: attrs<22.0.0,>=19.2.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from alibi) (20.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: requests<3.0.0,>=2.21.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from alibi) (2.25.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.16.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from alibi) (1.22.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pandas<2.0.0,>=0.23.3->alibi) (2021.1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Acer\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.21.0->alibi) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.21.0->alibi) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.21.0->alibi) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.21.0->alibi) (2020.12.5)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from scikit-image!=0.17.1,<0.20,>=0.14.2->alibi) (2.5)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from scikit-image!=0.17.1,<0.20,>=0.14.2->alibi) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from scikit-image!=0.17.1,<0.20,>=0.14.2->alibi) (2021.4.8)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from scikit-image!=0.17.1,<0.20,>=0.14.2->alibi) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from scikit-learn<1.1.0,>=0.20.2->alibi) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from scikit-learn<1.1.0,>=0.20.2->alibi) (1.0.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (0.9.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (2.11.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (20.9)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (8.0.15)\n",
      "Requirement already satisfied: setuptools in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (52.0.0.post20210125)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (0.7.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (2.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (3.0.9)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (1.0.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (2.4.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (1.0.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (1.8.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (3.0.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (0.4.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (0.6.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (3.3.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (2.0.7)\n",
      "Requirement already satisfied: spacy-lookups-data<1.1.0,>=1.0.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (1.0.3)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (2.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (0.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (1.12.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (2.7.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (2.7.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (2.7.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (1.43.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (3.19.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (2.10.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (0.36.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (0.23.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (3.3.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (1.0.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (12.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (1.15.0)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.7.0->alibi) (0.0.49)\n",
      "Requirement already satisfied: filelock in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.7.0->alibi) (3.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.7.0->alibi) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\acer\\appdata\\roaming\\python\\python38\\site-packages (from transformers<5.0.0,>=4.7.0->alibi) (2021.9.30)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.7.0->alibi) (0.12.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.7.0->alibi) (0.5.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from networkx>=2.0->scikit-image!=0.17.1,<0.20,>=0.14.2->alibi) (5.0.6)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy[lookups]<4.0.0,>=2.0.0->alibi) (5.2.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (2.3.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (3.3.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy[lookups]<4.0.0,>=2.0.0->alibi) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\acer\\appdata\\roaming\\python\\python38\\site-packages (from jinja2->spacy[lookups]<4.0.0,>=2.0.0->alibi) (2.0.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (4.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "pip install alibi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c076e389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from alibi.explainers import CounterfactualProto\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model,load_model\n",
    "tf.get_logger().setLevel(40) # Only error will be printed, not warning or info messages\n",
    "tf.compat.v1.disable_v2_behavior() # disable TF2 behaviour as alibi code still relies on TF1 constructs \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from alibi.utils.mapping import ohe_to_ord, ord_to_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "351f504c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Job</th>\n",
       "      <th>Housing</th>\n",
       "      <th>Saving accounts</th>\n",
       "      <th>Checking account</th>\n",
       "      <th>Credit amount</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>own</td>\n",
       "      <td>NaN</td>\n",
       "      <td>little</td>\n",
       "      <td>1169</td>\n",
       "      <td>6</td>\n",
       "      <td>radio/TV</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>moderate</td>\n",
       "      <td>5951</td>\n",
       "      <td>48</td>\n",
       "      <td>radio/TV</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2096</td>\n",
       "      <td>12</td>\n",
       "      <td>education</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>free</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>7882</td>\n",
       "      <td>42</td>\n",
       "      <td>furniture/equipment</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>free</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>4870</td>\n",
       "      <td>24</td>\n",
       "      <td>car</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1736</td>\n",
       "      <td>12</td>\n",
       "      <td>furniture/equipment</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>40</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>3857</td>\n",
       "      <td>30</td>\n",
       "      <td>car</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>38</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>NaN</td>\n",
       "      <td>804</td>\n",
       "      <td>12</td>\n",
       "      <td>radio/TV</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>23</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>free</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>1845</td>\n",
       "      <td>45</td>\n",
       "      <td>radio/TV</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>own</td>\n",
       "      <td>moderate</td>\n",
       "      <td>moderate</td>\n",
       "      <td>4576</td>\n",
       "      <td>45</td>\n",
       "      <td>car</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age     Sex  Job Housing Saving accounts Checking account  Credit amount  \\\n",
       "0     67    male    2     own             NaN           little           1169   \n",
       "1     22  female    2     own          little         moderate           5951   \n",
       "2     49    male    1     own          little              NaN           2096   \n",
       "3     45    male    2    free          little           little           7882   \n",
       "4     53    male    2    free          little           little           4870   \n",
       "..   ...     ...  ...     ...             ...              ...            ...   \n",
       "995   31  female    1     own          little              NaN           1736   \n",
       "996   40    male    3     own          little           little           3857   \n",
       "997   38    male    2     own          little              NaN            804   \n",
       "998   23    male    2    free          little           little           1845   \n",
       "999   27    male    2     own        moderate         moderate           4576   \n",
       "\n",
       "     Duration              Purpose  Risk  \n",
       "0           6             radio/TV  good  \n",
       "1          48             radio/TV   bad  \n",
       "2          12            education  good  \n",
       "3          42  furniture/equipment  good  \n",
       "4          24                  car   bad  \n",
       "..        ...                  ...   ...  \n",
       "995        12  furniture/equipment  good  \n",
       "996        30                  car  good  \n",
       "997        12             radio/TV  good  \n",
       "998        45             radio/TV   bad  \n",
       "999        45                  car  good  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"german_credit_data.csv\", index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8046a53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                 False\n",
       "Sex                 False\n",
       "Job                 False\n",
       "Housing             False\n",
       "Saving accounts      True\n",
       "Checking account     True\n",
       "Credit amount       False\n",
       "Duration            False\n",
       "Purpose             False\n",
       "Risk                False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9abef630",
   "metadata": {},
   "outputs": [],
   "source": [
    " def replace_missingValue_with_mode(dataFrame):\n",
    "    \n",
    "    columns_with_missing_value = dataFrame.columns[dataFrame.isnull().any()]\n",
    "    \n",
    "    for col in columns_with_missing_value:\n",
    "        col_mode = dataFrame[col].mode()[0]\n",
    "        dataFrame[col].fillna(col_mode, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91e6d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_missingValue_with_mode(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cc81792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                 False\n",
       "Sex                 False\n",
       "Job                 False\n",
       "Housing             False\n",
       "Saving accounts     False\n",
       "Checking account    False\n",
       "Credit amount       False\n",
       "Duration            False\n",
       "Purpose             False\n",
       "Risk                False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "712eca53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex\n",
      "male      690\n",
      "female    310\n",
      "Name: Sex, dtype: int64\n",
      "1    690\n",
      "0    310\n",
      "Name: Sex, dtype: int64\n",
      "Housing\n",
      "own     713\n",
      "rent    179\n",
      "free    108\n",
      "Name: Housing, dtype: int64\n",
      "1    713\n",
      "2    179\n",
      "0    108\n",
      "Name: Housing, dtype: int64\n",
      "Saving accounts\n",
      "little        786\n",
      "moderate      103\n",
      "quite rich     63\n",
      "rich           48\n",
      "Name: Saving accounts, dtype: int64\n",
      "0    786\n",
      "1    103\n",
      "2     63\n",
      "3     48\n",
      "Name: Saving accounts, dtype: int64\n",
      "Checking account\n",
      "little      668\n",
      "moderate    269\n",
      "rich         63\n",
      "Name: Checking account, dtype: int64\n",
      "0    668\n",
      "1    269\n",
      "2     63\n",
      "Name: Checking account, dtype: int64\n",
      "Purpose\n",
      "car                    337\n",
      "radio/TV               280\n",
      "furniture/equipment    181\n",
      "business                97\n",
      "education               59\n",
      "repairs                 22\n",
      "domestic appliances     12\n",
      "vacation/others         12\n",
      "Name: Purpose, dtype: int64\n",
      "1    337\n",
      "5    280\n",
      "4    181\n",
      "0     97\n",
      "3     59\n",
      "6     22\n",
      "2     12\n",
      "7     12\n",
      "Name: Purpose, dtype: int64\n",
      "Risk\n",
      "good    700\n",
      "bad     300\n",
      "Name: Risk, dtype: int64\n",
      "1    700\n",
      "0    300\n",
      "Name: Risk, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Job</th>\n",
       "      <th>Housing</th>\n",
       "      <th>Saving accounts</th>\n",
       "      <th>Checking account</th>\n",
       "      <th>Credit amount</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1169</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5951</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2096</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7882</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4870</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1736</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3857</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>804</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1845</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4576</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Sex  Job  Housing  Saving accounts  Checking account  Credit amount  \\\n",
       "0     67    1    2        1                0                 0           1169   \n",
       "1     22    0    2        1                0                 1           5951   \n",
       "2     49    1    1        1                0                 0           2096   \n",
       "3     45    1    2        0                0                 0           7882   \n",
       "4     53    1    2        0                0                 0           4870   \n",
       "..   ...  ...  ...      ...              ...               ...            ...   \n",
       "995   31    0    1        1                0                 0           1736   \n",
       "996   40    1    3        1                0                 0           3857   \n",
       "997   38    1    2        1                0                 0            804   \n",
       "998   23    1    2        0                0                 0           1845   \n",
       "999   27    1    2        1                1                 1           4576   \n",
       "\n",
       "     Duration  Purpose  Risk  \n",
       "0           6        5     1  \n",
       "1          48        5     0  \n",
       "2          12        3     1  \n",
       "3          42        4     1  \n",
       "4          24        1     0  \n",
       "..        ...      ...   ...  \n",
       "995        12        4     1  \n",
       "996        30        1     1  \n",
       "997        12        5     1  \n",
       "998        45        5     0  \n",
       "999        45        1     1  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label encoder: Encode target labels with value between 0 and n_classes-1\n",
    "\n",
    "def categorical_to_numeric(df):\n",
    "    labelencoder= LabelEncoder()\n",
    "    for col in df.columns.to_list():\n",
    "        if(df[col].dtype == \"object\"):\n",
    "            print(col)\n",
    "            print(df[col].value_counts())\n",
    "            df[col] = labelencoder.fit_transform(df[col])\n",
    "            print(df[col].value_counts())\n",
    "    return df\n",
    "df_new = categorical_to_numeric(df.copy())\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a68d1a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,    2,    1, ...,   67, 1169,    6],\n",
       "       [   0,    2,    1, ...,   22, 5951,   48],\n",
       "       [   1,    1,    1, ...,   49, 2096,   12],\n",
       "       ...,\n",
       "       [   1,    2,    1, ...,   38,  804,   12],\n",
       "       [   1,    2,    0, ...,   23, 1845,   45],\n",
       "       [   1,    2,    1, ...,   27, 4576,   45]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.c_[df_new.iloc[:,1:6], df_new.iloc[:,8:9], df_new.iloc[:,0:1], df_new.iloc[:,6:8]]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26780b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 2, 2: 4, 6: 3, 9: 4, 13: 3, 16: 8}\n"
     ]
    }
   ],
   "source": [
    "cate_dict={0: 2, 1: 4, 2: 3, 3: 4, 4: 3, 5: 8}\n",
    "cat_vars_ohe = ord_to_ohe(X, cate_dict)\n",
    "cat_vars_ohe = cat_vars_ohe[1]\n",
    "print(cat_vars_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb928246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 1, 0, 0, 5],\n",
       "       [0, 2, 1, 0, 1, 5],\n",
       "       [1, 1, 1, 0, 0, 3],\n",
       "       ...,\n",
       "       [1, 2, 1, 0, 0, 5],\n",
       "       [1, 2, 0, 0, 0, 5],\n",
       "       [1, 2, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4cf8e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert ordinal values to One Hot encoding\n",
    "ohe = OneHotEncoder(categories='auto')\n",
    "ohe.fit(X[:,:-3])\n",
    "X_ohe = ohe.transform(X[:,:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7e1515a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x24 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe117ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 1., 0., ..., 1., 0., 0.],\n",
       "        [1., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0., ..., 1., 0., 0.],\n",
       "        [0., 1., 0., ..., 1., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ohe.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe3f1c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  Credit amount  Duration\n",
      "0     67           1169         6\n",
      "1     22           5951        48\n",
      "2     49           2096        12\n",
      "3     45           7882        42\n",
      "4     53           4870        24\n",
      "..   ...            ...       ...\n",
      "995   31           1736        12\n",
      "996   40           3857        30\n",
      "997   38            804        12\n",
      "998   23           1845        45\n",
      "999   27           4576        45\n",
      "\n",
      "[1000 rows x 3 columns]\n",
      "Age                35.546\n",
      "Credit amount    3271.258\n",
      "Duration           20.903\n",
      "dtype: float64\n",
      "Age                11.375469\n",
      "Credit amount    2822.736876\n",
      "Duration           12.058814\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Credit amount</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.765073</td>\n",
       "      <td>-0.744759</td>\n",
       "      <td>-1.235859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.190808</td>\n",
       "      <td>0.949342</td>\n",
       "      <td>2.247070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.182721</td>\n",
       "      <td>-0.416354</td>\n",
       "      <td>-0.738298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.831087</td>\n",
       "      <td>1.633430</td>\n",
       "      <td>1.749509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.534354</td>\n",
       "      <td>0.566380</td>\n",
       "      <td>0.256825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-0.399632</td>\n",
       "      <td>-0.543890</td>\n",
       "      <td>-0.738298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.391544</td>\n",
       "      <td>0.207509</td>\n",
       "      <td>0.754386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.215727</td>\n",
       "      <td>-0.874066</td>\n",
       "      <td>-0.738298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-1.102900</td>\n",
       "      <td>-0.505275</td>\n",
       "      <td>1.998289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-0.751266</td>\n",
       "      <td>0.462226</td>\n",
       "      <td>1.998289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age  Credit amount  Duration\n",
       "0    2.765073      -0.744759 -1.235859\n",
       "1   -1.190808       0.949342  2.247070\n",
       "2    1.182721      -0.416354 -0.738298\n",
       "3    0.831087       1.633430  1.749509\n",
       "4    1.534354       0.566380  0.256825\n",
       "..        ...            ...       ...\n",
       "995 -0.399632      -0.543890 -0.738298\n",
       "996  0.391544       0.207509  0.754386\n",
       "997  0.215727      -0.874066 -0.738298\n",
       "998 -1.102900      -0.505275  1.998289\n",
       "999 -0.751266       0.462226  1.998289\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Standardize the numerical columns\n",
    "x_num = pd.concat([df_new.iloc[:,0:1], df_new.iloc[:,6:8]], axis=1)\n",
    "print(x_num)\n",
    "mu = x_num.mean(axis=0)\n",
    "print(mu)\n",
    "sigma = x_num.std(axis=0)\n",
    "print(sigma)\n",
    "x_num= (x_num - mu) / sigma\n",
    "x_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e584def3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.        ,  1.        ,  0.        , ..., -0.74475875,\n",
       "         -1.23585947,  1.        ],\n",
       "        [ 1.        ,  0.        ,  0.        , ...,  0.94934176,\n",
       "          2.24706998,  0.        ],\n",
       "        [ 0.        ,  1.        ,  0.        , ..., -0.41635407,\n",
       "         -0.73829812,  1.        ],\n",
       "        ...,\n",
       "        [ 0.        ,  1.        ,  0.        , ..., -0.87406588,\n",
       "         -0.73829812,  1.        ],\n",
       "        [ 0.        ,  1.        ,  0.        , ..., -0.50527487,\n",
       "          1.99828931,  0.        ],\n",
       "        [ 0.        ,  1.        ,  0.        , ...,  0.46222587,\n",
       "          1.99828931,  1.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenate the modified categorical and numerical columns\n",
    "df_clean =  np.c_[X_ohe.todense(), x_num, df_new.iloc[:,-1:]]\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1428df74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 28)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f13cea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df_clean, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b39dc3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train=train_data[:,:-1],train_data[:,-1:]\n",
    "x_test,y_test=test_data[:,:-1],test_data[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffe24bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model():\n",
    "    x_in = Input(shape=(27,))\n",
    "    x = Dense(18, activation='relu')(x_in)\n",
    "#     x = Dense(9, activation='softmax')(x)\n",
    "    x_out_l = Dense(2, activation='sigmoid')(x)\n",
    "    nn = Model(inputs=x_in, outputs=x_out_l)\n",
    "    nn.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    return nn\n",
    "#the sigmoid is a function that only occupies the range from 0 to 1 and it asymptotes both values. This makes it very handy for binary classification with 0 and 1 as potential output values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d015a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 27)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 18)                504       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 38        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 542\n",
      "Trainable params: 542\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 800 samples\n",
      "Epoch 1/200\n",
      "800/800 [==============================] - 0s 135us/sample - loss: 0.6126 - acc: 0.6900\n",
      "Epoch 2/200\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5994 - acc: 0.6875\n",
      "Epoch 3/200\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.5936 - acc: 0.6938\n",
      "Epoch 4/200\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.5896 - acc: 0.6975\n",
      "Epoch 5/200\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.5865 - acc: 0.6950\n",
      "Epoch 6/200\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5840 - acc: 0.7025\n",
      "Epoch 7/200\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5822 - acc: 0.6963\n",
      "Epoch 8/200\n",
      "800/800 [==============================] - 0s 61us/sample - loss: 0.5807 - acc: 0.6925\n",
      "Epoch 9/200\n",
      "800/800 [==============================] - 0s 68us/sample - loss: 0.5788 - acc: 0.6950\n",
      "Epoch 10/200\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.5772 - acc: 0.7000\n",
      "Epoch 11/200\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.5768 - acc: 0.6950\n",
      "Epoch 12/200\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 0.5749 - acc: 0.6988\n",
      "Epoch 13/200\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.5738 - acc: 0.7013\n",
      "Epoch 14/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 0.5728 - acc: 0.7025\n",
      "Epoch 15/200\n",
      "800/800 [==============================] - 0s 66us/sample - loss: 0.5717 - acc: 0.7000\n",
      "Epoch 16/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 0.5708 - acc: 0.6988\n",
      "Epoch 17/200\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 0.5701 - acc: 0.7025\n",
      "Epoch 18/200\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 0.5694 - acc: 0.7063\n",
      "Epoch 19/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.5678 - acc: 0.7075\n",
      "Epoch 20/200\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.5678 - acc: 0.7050\n",
      "Epoch 21/200\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5670 - acc: 0.7050\n",
      "Epoch 22/200\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.5660 - acc: 0.7063\n",
      "Epoch 23/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 0.5652 - acc: 0.7038\n",
      "Epoch 24/200\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.5649 - acc: 0.7100\n",
      "Epoch 25/200\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 0.5646 - acc: 0.7050\n",
      "Epoch 26/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 0.5633 - acc: 0.7075\n",
      "Epoch 27/200\n",
      "800/800 [==============================] - 0s 77us/sample - loss: 0.5618 - acc: 0.7050\n",
      "Epoch 28/200\n",
      "800/800 [==============================] - 0s 85us/sample - loss: 0.5622 - acc: 0.7138\n",
      "Epoch 29/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.5611 - acc: 0.7088\n",
      "Epoch 30/200\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 0.5605 - acc: 0.7038\n",
      "Epoch 31/200\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 0.5597 - acc: 0.7150\n",
      "Epoch 32/200\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.5589 - acc: 0.7100\n",
      "Epoch 33/200\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 0.5580 - acc: 0.7088\n",
      "Epoch 34/200\n",
      "800/800 [==============================] - 0s 82us/sample - loss: 0.5577 - acc: 0.7075\n",
      "Epoch 35/200\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 0.5570 - acc: 0.7237\n",
      "Epoch 36/200\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.5568 - acc: 0.7188\n",
      "Epoch 37/200\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 0.5558 - acc: 0.7150\n",
      "Epoch 38/200\n",
      "800/800 [==============================] - 0s 71us/sample - loss: 0.5549 - acc: 0.7225\n",
      "Epoch 39/200\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.5541 - acc: 0.7237\n",
      "Epoch 40/200\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 0.5531 - acc: 0.7200\n",
      "Epoch 41/200\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.5527 - acc: 0.7250\n",
      "Epoch 42/200\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.5523 - acc: 0.7212\n",
      "Epoch 43/200\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.5515 - acc: 0.7262\n",
      "Epoch 44/200\n",
      "800/800 [==============================] - 0s 63us/sample - loss: 0.5508 - acc: 0.7212\n",
      "Epoch 45/200\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 0.5507 - acc: 0.7225\n",
      "Epoch 46/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 0.5499 - acc: 0.7275\n",
      "Epoch 47/200\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5491 - acc: 0.7163\n",
      "Epoch 48/200\n",
      "800/800 [==============================] - 0s 67us/sample - loss: 0.5484 - acc: 0.7250\n",
      "Epoch 49/200\n",
      "800/800 [==============================] - 0s 82us/sample - loss: 0.5480 - acc: 0.7237\n",
      "Epoch 50/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 0.5472 - acc: 0.7262\n",
      "Epoch 51/200\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.5466 - acc: 0.7250\n",
      "Epoch 52/200\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 0.5459 - acc: 0.7237\n",
      "Epoch 53/200\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5452 - acc: 0.7237\n",
      "Epoch 54/200\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5445 - acc: 0.7262\n",
      "Epoch 55/200\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5441 - acc: 0.7312\n",
      "Epoch 56/200\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5427 - acc: 0.7287\n",
      "Epoch 57/200\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5430 - acc: 0.7262\n",
      "Epoch 58/200\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5416 - acc: 0.7287\n",
      "Epoch 59/200\n",
      "800/800 [==============================] - 0s 52us/sample - loss: 0.5422 - acc: 0.7250\n",
      "Epoch 60/200\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5409 - acc: 0.7262\n",
      "Epoch 61/200\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.5400 - acc: 0.7250\n",
      "Epoch 62/200\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5394 - acc: 0.7275\n",
      "Epoch 63/200\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5389 - acc: 0.7275\n",
      "Epoch 64/200\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.5384 - acc: 0.7275\n",
      "Epoch 65/200\n",
      "800/800 [==============================] - 0s 86us/sample - loss: 0.5381 - acc: 0.7325\n",
      "Epoch 66/200\n",
      "800/800 [==============================] - 0s 169us/sample - loss: 0.5376 - acc: 0.7300\n",
      "Epoch 67/200\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.5360 - acc: 0.7387\n",
      "Epoch 68/200\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 0.5357 - acc: 0.7325\n",
      "Epoch 69/200\n",
      "800/800 [==============================] - 0s 123us/sample - loss: 0.5357 - acc: 0.7325\n",
      "Epoch 70/200\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 0.5346 - acc: 0.7350\n",
      "Epoch 71/200\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.5339 - acc: 0.7350\n",
      "Epoch 72/200\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 0.5336 - acc: 0.7350\n",
      "Epoch 73/200\n",
      "800/800 [==============================] - 0s 120us/sample - loss: 0.5330 - acc: 0.7375\n",
      "Epoch 74/200\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 0.5319 - acc: 0.7412\n",
      "Epoch 75/200\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 0.5324 - acc: 0.7362\n",
      "Epoch 76/200\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 0.5313 - acc: 0.7387\n",
      "Epoch 77/200\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 0.5312 - acc: 0.7350\n",
      "Epoch 78/200\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 0.5298 - acc: 0.7425\n",
      "Epoch 79/200\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 0.5297 - acc: 0.7375\n",
      "Epoch 80/200\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 0.5286 - acc: 0.7487\n",
      "Epoch 81/200\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 0.5282 - acc: 0.7400\n",
      "Epoch 82/200\n",
      "800/800 [==============================] - 0s 116us/sample - loss: 0.5279 - acc: 0.7412\n",
      "Epoch 83/200\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 0.5271 - acc: 0.7425\n",
      "Epoch 84/200\n",
      "800/800 [==============================] - 0s 117us/sample - loss: 0.5269 - acc: 0.7437\n",
      "Epoch 85/200\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 0.5263 - acc: 0.7475\n",
      "Epoch 86/200\n",
      "800/800 [==============================] - 0s 54us/sample - loss: 0.5256 - acc: 0.7425\n",
      "Epoch 87/200\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.5245 - acc: 0.7475\n",
      "Epoch 88/200\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.5246 - acc: 0.7425\n",
      "Epoch 89/200\n",
      "800/800 [==============================] - 0s 45us/sample - loss: 0.5243 - acc: 0.7500\n",
      "Epoch 90/200\n",
      "800/800 [==============================] - 0s 60us/sample - loss: 0.5229 - acc: 0.7475\n",
      "Epoch 91/200\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 0.5231 - acc: 0.7487\n",
      "Epoch 92/200\n",
      "800/800 [==============================] - 0s 56us/sample - loss: 0.5224 - acc: 0.7500\n",
      "Epoch 93/200\n",
      "800/800 [==============================] - 0s 62us/sample - loss: 0.5224 - acc: 0.7500\n",
      "Epoch 94/200\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.5215 - acc: 0.7450\n",
      "Epoch 95/200\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5210 - acc: 0.7437\n",
      "Epoch 96/200\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.5205 - acc: 0.7513\n",
      "Epoch 97/200\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.5192 - acc: 0.7475\n",
      "Epoch 98/200\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.5188 - acc: 0.7525\n",
      "Epoch 99/200\n",
      "800/800 [==============================] - 0s 55us/sample - loss: 0.5183 - acc: 0.7550\n",
      "Epoch 100/200\n",
      "800/800 [==============================] - 0s 45us/sample - loss: 0.5181 - acc: 0.7525\n",
      "Epoch 101/200\n",
      "800/800 [==============================] - 0s 45us/sample - loss: 0.5177 - acc: 0.7513\n",
      "Epoch 102/200\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.5165 - acc: 0.7550\n",
      "Epoch 103/200\n",
      "800/800 [==============================] - 0s 46us/sample - loss: 0.5167 - acc: 0.7500\n",
      "Epoch 104/200\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.5159 - acc: 0.7550\n",
      "Epoch 105/200\n",
      "800/800 [==============================] - 0s 45us/sample - loss: 0.5154 - acc: 0.7563\n",
      "Epoch 106/200\n",
      "800/800 [==============================] - 0s 43us/sample - loss: 0.5150 - acc: 0.7550\n",
      "Epoch 107/200\n",
      "800/800 [==============================] - 0s 78us/sample - loss: 0.5139 - acc: 0.7513\n",
      "Epoch 108/200\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 0.5134 - acc: 0.7613\n",
      "Epoch 109/200\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.5130 - acc: 0.7575\n",
      "Epoch 110/200\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.5126 - acc: 0.7538\n",
      "Epoch 111/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 0.5119 - acc: 0.7600\n",
      "Epoch 112/200\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.5109 - acc: 0.7513\n",
      "Epoch 113/200\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.5111 - acc: 0.7525\n",
      "Epoch 114/200\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.5107 - acc: 0.7575\n",
      "Epoch 115/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.5097 - acc: 0.7550\n",
      "Epoch 116/200\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 0.5098 - acc: 0.7588\n",
      "Epoch 117/200\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.5087 - acc: 0.7600\n",
      "Epoch 118/200\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.5081 - acc: 0.7538\n",
      "Epoch 119/200\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 0.5078 - acc: 0.7613\n",
      "Epoch 120/200\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 0.5074 - acc: 0.7625\n",
      "Epoch 121/200\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 0.5069 - acc: 0.7588\n",
      "Epoch 122/200\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.5064 - acc: 0.7638\n",
      "Epoch 123/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 0.5063 - acc: 0.7625\n",
      "Epoch 124/200\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.5060 - acc: 0.7613\n",
      "Epoch 125/200\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 0.5040 - acc: 0.7600\n",
      "Epoch 126/200\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.5048 - acc: 0.7625\n",
      "Epoch 127/200\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.5027 - acc: 0.7588\n",
      "Epoch 128/200\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.5032 - acc: 0.7538\n",
      "Epoch 129/200\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.5030 - acc: 0.7663\n",
      "Epoch 130/200\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 0.5022 - acc: 0.7650\n",
      "Epoch 131/200\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.5014 - acc: 0.7688\n",
      "Epoch 132/200\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.5012 - acc: 0.7613\n",
      "Epoch 133/200\n",
      "800/800 [==============================] - 0s 72us/sample - loss: 0.5007 - acc: 0.7650\n",
      "Epoch 134/200\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 0.5001 - acc: 0.7675\n",
      "Epoch 135/200\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 0.5003 - acc: 0.7688\n",
      "Epoch 136/200\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.4985 - acc: 0.7675\n",
      "Epoch 137/200\n",
      "800/800 [==============================] - 0s 102us/sample - loss: 0.4980 - acc: 0.7650\n",
      "Epoch 138/200\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.4981 - acc: 0.7663\n",
      "Epoch 139/200\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.4978 - acc: 0.7663\n",
      "Epoch 140/200\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 0.4984 - acc: 0.7700\n",
      "Epoch 141/200\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.4946 - acc: 0.7688\n",
      "Epoch 142/200\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.4972 - acc: 0.7663\n",
      "Epoch 143/200\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 0.4969 - acc: 0.7713\n",
      "Epoch 144/200\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.4957 - acc: 0.7613\n",
      "Epoch 145/200\n",
      "800/800 [==============================] - 0s 86us/sample - loss: 0.4949 - acc: 0.7700\n",
      "Epoch 146/200\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4952 - acc: 0.7725\n",
      "Epoch 147/200\n",
      "800/800 [==============================] - 0s 46us/sample - loss: 0.4948 - acc: 0.7625\n",
      "Epoch 148/200\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 0.4943 - acc: 0.7650\n",
      "Epoch 149/200\n",
      "800/800 [==============================] - 0s 46us/sample - loss: 0.4935 - acc: 0.7688\n",
      "Epoch 150/200\n",
      "800/800 [==============================] - 0s 46us/sample - loss: 0.4928 - acc: 0.7688\n",
      "Epoch 151/200\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.4925 - acc: 0.7738\n",
      "Epoch 152/200\n",
      "800/800 [==============================] - 0s 49us/sample - loss: 0.4912 - acc: 0.7725\n",
      "Epoch 153/200\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4918 - acc: 0.7700\n",
      "Epoch 154/200\n",
      "800/800 [==============================] - 0s 109us/sample - loss: 0.4893 - acc: 0.7725\n",
      "Epoch 155/200\n",
      "800/800 [==============================] - 0s 118us/sample - loss: 0.4914 - acc: 0.7663\n",
      "Epoch 156/200\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4905 - acc: 0.7750\n",
      "Epoch 157/200\n",
      "800/800 [==============================] - 0s 45us/sample - loss: 0.4899 - acc: 0.7650\n",
      "Epoch 158/200\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.4880 - acc: 0.7675\n",
      "Epoch 159/200\n",
      "800/800 [==============================] - 0s 86us/sample - loss: 0.4881 - acc: 0.7725\n",
      "Epoch 160/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 0.4885 - acc: 0.7713\n",
      "Epoch 161/200\n",
      "800/800 [==============================] - 0s 111us/sample - loss: 0.4871 - acc: 0.7713\n",
      "Epoch 162/200\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.4872 - acc: 0.7700\n",
      "Epoch 163/200\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.4862 - acc: 0.7713\n",
      "Epoch 164/200\n",
      "800/800 [==============================] - 0s 81us/sample - loss: 0.4868 - acc: 0.7750\n",
      "Epoch 165/200\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.4855 - acc: 0.7738\n",
      "Epoch 166/200\n",
      "800/800 [==============================] - 0s 58us/sample - loss: 0.4839 - acc: 0.7725\n",
      "Epoch 167/200\n",
      "800/800 [==============================] - 0s 46us/sample - loss: 0.4838 - acc: 0.7675\n",
      "Epoch 168/200\n",
      "800/800 [==============================] - 0s 50us/sample - loss: 0.4852 - acc: 0.7750\n",
      "Epoch 169/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.4831 - acc: 0.7650\n",
      "Epoch 170/200\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.4825 - acc: 0.7775\n",
      "Epoch 171/200\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.4819 - acc: 0.7725\n",
      "Epoch 172/200\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.4816 - acc: 0.7688\n",
      "Epoch 173/200\n",
      "800/800 [==============================] - 0s 106us/sample - loss: 0.4804 - acc: 0.7800\n",
      "Epoch 174/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.4807 - acc: 0.7763\n",
      "Epoch 175/200\n",
      "800/800 [==============================] - 0s 73us/sample - loss: 0.4804 - acc: 0.7725\n",
      "Epoch 176/200\n",
      "800/800 [==============================] - 0s 84us/sample - loss: 0.4793 - acc: 0.7713\n",
      "Epoch 177/200\n",
      "800/800 [==============================] - 0s 81us/sample - loss: 0.4794 - acc: 0.7800\n",
      "Epoch 178/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 0.4777 - acc: 0.7738\n",
      "Epoch 179/200\n",
      "800/800 [==============================] - 0s 105us/sample - loss: 0.4782 - acc: 0.7713\n",
      "Epoch 180/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 0.4764 - acc: 0.7812\n",
      "Epoch 181/200\n",
      "800/800 [==============================] - 0s 80us/sample - loss: 0.4771 - acc: 0.7738\n",
      "Epoch 182/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 0.4774 - acc: 0.7800\n",
      "Epoch 183/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.4762 - acc: 0.7825\n",
      "Epoch 184/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 0.4756 - acc: 0.7812\n",
      "Epoch 185/200\n",
      "800/800 [==============================] - 0s 53us/sample - loss: 0.4748 - acc: 0.7775\n",
      "Epoch 186/200\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.4735 - acc: 0.7812\n",
      "Epoch 187/200\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.4737 - acc: 0.7788\n",
      "Epoch 188/200\n",
      "800/800 [==============================] - 0s 45us/sample - loss: 0.4730 - acc: 0.7750\n",
      "Epoch 189/200\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.4725 - acc: 0.7825\n",
      "Epoch 190/200\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4722 - acc: 0.7825\n",
      "Epoch 191/200\n",
      "800/800 [==============================] - 0s 45us/sample - loss: 0.4700 - acc: 0.7825\n",
      "Epoch 192/200\n",
      "800/800 [==============================] - 0s 46us/sample - loss: 0.4715 - acc: 0.7775\n",
      "Epoch 193/200\n",
      "800/800 [==============================] - 0s 46us/sample - loss: 0.4703 - acc: 0.7837\n",
      "Epoch 194/200\n",
      "800/800 [==============================] - 0s 47us/sample - loss: 0.4706 - acc: 0.7812\n",
      "Epoch 195/200\n",
      "800/800 [==============================] - 0s 48us/sample - loss: 0.4694 - acc: 0.7837\n",
      "Epoch 196/200\n",
      "800/800 [==============================] - 0s 51us/sample - loss: 0.4686 - acc: 0.7862\n",
      "Epoch 197/200\n",
      "800/800 [==============================] - 0s 57us/sample - loss: 0.4686 - acc: 0.7837\n",
      "Epoch 198/200\n",
      "800/800 [==============================] - 0s 76us/sample - loss: 0.4677 - acc: 0.7763\n",
      "Epoch 199/200\n",
      "800/800 [==============================] - 0s 107us/sample - loss: 0.4688 - acc: 0.7800\n",
      "Epoch 200/200\n",
      "800/800 [==============================] - 0s 112us/sample - loss: 0.4669 - acc: 0.7862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d86e3f55b0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = nn_model()\n",
    "nn.summary()\n",
    "nn.fit(x_train, y_train, batch_size=10, epochs=200, verbose=1)\n",
    "#output_size * (input_size + 1) == number_parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "893d2585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    }
   ],
   "source": [
    "score = nn.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0788e0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 [<keras.engine.node.Node object at 0x000001D86E34BDC0>] [<keras.engine.node.Node object at 0x000001D86E35D820>]\n",
      "dense [<keras.engine.node.Node object at 0x000001D86E35D820>] [<keras.engine.node.Node object at 0x000001D86E35D610>]\n",
      "dense_1 [<keras.engine.node.Node object at 0x000001D86E35D610>] []\n"
     ]
    }
   ],
   "source": [
    "for layer in nn.layers:\n",
    "    print(layer.name, layer.inbound_nodes, layer.outbound_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1762dc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense/kernel:0 (27, 18)\n",
      "dense/bias:0 (18,)\n",
      "dense_1/kernel:0 (18, 2)\n",
      "dense_1/bias:0 (2,)\n",
      "<keras.engine.input_layer.InputLayer object at 0x000001D86E1E07F0> ---------- [array([[ 2.03999087e-01, -1.28053084e-01,  2.51313955e-01,\n",
      "         2.17519537e-01, -3.85622919e-01, -2.66590148e-01,\n",
      "        -6.35308474e-02,  3.64601277e-02, -9.65961143e-02,\n",
      "         3.32777709e-01,  1.93458274e-01,  3.26159805e-01,\n",
      "         9.57212746e-02, -6.75269067e-02,  2.37667665e-01,\n",
      "        -2.67305911e-01,  9.46578905e-02, -1.99721649e-01],\n",
      "       [-9.73574147e-02, -5.87192923e-02, -1.46250157e-02,\n",
      "         3.52003157e-01,  3.36519897e-01, -2.04159990e-01,\n",
      "        -3.80150437e-01,  3.19869280e-01, -8.93107131e-02,\n",
      "        -1.98329724e-02,  2.38479704e-01, -3.18224043e-01,\n",
      "         2.32561097e-01, -1.25210807e-01, -5.98012030e-01,\n",
      "        -4.82303929e-03, -1.40538469e-01,  6.90590218e-02],\n",
      "       [-2.53820360e-01,  1.98137179e-01,  1.41085058e-01,\n",
      "        -1.87789813e-01, -2.18788221e-01, -3.34584951e-01,\n",
      "        -4.86251265e-02, -2.80405760e-01, -3.78104925e-01,\n",
      "        -1.02975234e-01,  2.85323232e-01, -7.44003803e-02,\n",
      "         2.83436447e-01,  2.45306920e-02, -3.17602843e-01,\n",
      "        -1.42352104e-01,  8.36716667e-02,  1.38371587e-01],\n",
      "       [-2.56447345e-01, -4.60955083e-01, -3.77201915e-01,\n",
      "        -7.41861090e-02,  3.23065162e-01, -3.56690705e-01,\n",
      "        -4.58472483e-02, -2.72505730e-01, -7.88209364e-02,\n",
      "        -1.96065769e-01, -1.85968220e-01,  3.28815103e-01,\n",
      "         2.69453317e-01, -3.13699216e-01,  9.43450704e-02,\n",
      "        -2.02118918e-01,  5.86512983e-01, -1.14455022e-01],\n",
      "       [-1.22749992e-01,  2.25588769e-01,  2.50550687e-01,\n",
      "        -3.33043188e-02, -6.56295419e-02,  2.23870516e-01,\n",
      "         2.99711257e-01, -2.96986729e-01, -3.39677036e-01,\n",
      "         2.52314746e-01, -1.22885883e-01,  3.08383673e-01,\n",
      "         2.14228109e-01,  5.52572131e-01,  1.34447506e-02,\n",
      "         2.94843435e-01, -2.40881935e-01, -5.99842966e-01],\n",
      "       [-3.91466431e-02,  3.56668562e-01, -3.23144972e-01,\n",
      "        -3.44871581e-01,  1.06900536e-01,  7.21961632e-02,\n",
      "        -3.67444158e-02, -1.98092386e-01,  3.07729512e-01,\n",
      "         9.85339731e-02, -2.42755517e-01,  1.78677917e-01,\n",
      "         1.75265316e-02, -2.19190702e-01, -1.43023329e-02,\n",
      "         1.48601905e-01, -4.47912276e-01,  1.49233475e-01],\n",
      "       [ 7.11600110e-02, -3.50773990e-01, -8.30872729e-03,\n",
      "        -1.13942102e-01, -4.90959249e-02,  1.27996847e-01,\n",
      "         9.74756628e-02,  2.80071765e-01,  1.63929567e-01,\n",
      "         2.04042077e-01,  9.26570743e-02, -3.28351587e-01,\n",
      "        -2.72852451e-01, -2.10675076e-02, -1.03627376e-01,\n",
      "        -2.62052678e-02, -5.26757650e-02,  3.19823623e-01],\n",
      "       [-2.64720052e-01,  4.50532168e-01,  1.72275305e-01,\n",
      "        -3.38339270e-03,  1.64968088e-01,  1.01350946e-02,\n",
      "        -4.97991405e-02, -6.15504272e-02, -2.17155769e-01,\n",
      "         3.71200852e-02, -7.74002373e-02,  3.58352989e-01,\n",
      "         2.57448763e-01, -4.49516982e-01, -1.26433805e-01,\n",
      "        -2.05262788e-02,  1.19049698e-01, -3.81276041e-01],\n",
      "       [-4.84288932e-04, -2.80432940e-01, -1.34773090e-01,\n",
      "        -1.84680894e-01, -9.78314653e-02, -1.91739276e-01,\n",
      "         6.18840940e-02, -1.71238437e-01, -2.30825365e-01,\n",
      "        -3.84690762e-01, -3.01232696e-01,  2.69586295e-01,\n",
      "         3.16328555e-01,  2.71516919e-01, -1.04377151e-01,\n",
      "        -4.62715216e-02,  3.55194882e-02, -1.50954723e-01],\n",
      "       [-3.67641509e-01, -3.35773006e-02,  2.37671375e-01,\n",
      "        -4.74325791e-02,  9.15693492e-02, -2.62871593e-01,\n",
      "         2.00387701e-01, -2.08246365e-01, -1.08892530e-01,\n",
      "        -5.21442853e-02, -1.63908496e-01, -6.75659776e-01,\n",
      "        -8.86319131e-02,  5.52690625e-02, -3.89595777e-01,\n",
      "        -1.90289229e-01,  9.09255296e-02,  3.85529906e-01],\n",
      "       [ 2.31290162e-01,  1.68200061e-01, -4.07397524e-02,\n",
      "        -2.49302104e-01,  1.33522853e-01,  1.38746366e-01,\n",
      "        -2.49026239e-01,  1.12042733e-01,  4.27619457e-01,\n",
      "        -5.77793121e-02, -1.47379160e-01,  8.52758437e-02,\n",
      "         1.86023396e-02, -2.27688819e-01,  1.96391597e-01,\n",
      "        -3.29662830e-01,  9.39863473e-02, -1.22868605e-01],\n",
      "       [ 2.27850154e-02,  1.38270885e-01, -1.04958169e-01,\n",
      "        -1.40249163e-01,  8.33365694e-02,  2.18973309e-01,\n",
      "         1.42656937e-01, -1.75456211e-01, -3.04457366e-01,\n",
      "         3.86028849e-02,  1.06674604e-01, -1.24057174e-01,\n",
      "         4.43545908e-01, -1.60229132e-01,  2.04711467e-01,\n",
      "        -9.66126248e-02,  1.40200719e-01, -1.69717982e-01],\n",
      "       [-3.25753950e-02, -3.54403228e-01,  2.34008282e-01,\n",
      "        -1.71391964e-01, -1.89611432e-03,  2.57120430e-01,\n",
      "         2.18180612e-01,  1.37032904e-02, -1.31025210e-01,\n",
      "         1.99245796e-01, -2.05733478e-01,  1.77009180e-01,\n",
      "        -7.07801282e-02,  2.87792414e-01, -3.64929408e-01,\n",
      "        -3.29339951e-02, -3.03790092e-01, -7.98829552e-03],\n",
      "       [ 3.50744575e-02, -2.18501166e-01,  2.26974770e-01,\n",
      "         2.71234155e-01, -2.89094895e-01,  2.20593616e-01,\n",
      "        -2.25961301e-02, -3.47777666e-03, -2.40310505e-01,\n",
      "         2.52054143e-03, -2.47311622e-01,  3.36385369e-01,\n",
      "         1.43644493e-02,  4.14453894e-01, -2.22103655e-01,\n",
      "         1.24916933e-01,  4.11539197e-01, -2.69214460e-03],\n",
      "       [ 2.62427270e-01,  3.58384885e-02, -3.10837980e-02,\n",
      "        -4.38702881e-01,  1.27311110e-01, -2.31797218e-01,\n",
      "         7.10984021e-02,  1.84834376e-01, -7.11416006e-02,\n",
      "        -2.49229327e-01, -2.29427025e-01, -1.00606181e-01,\n",
      "        -1.36321872e-01,  1.26960248e-01,  4.61507857e-01,\n",
      "        -2.29719102e-01, -4.77916539e-01, -2.55627424e-01],\n",
      "       [ 1.69170797e-01, -2.67548442e-01,  3.72076988e-01,\n",
      "        -2.48567358e-01,  3.21369171e-01,  4.24694091e-01,\n",
      "         1.31925210e-01,  2.76547018e-02,  2.60763746e-02,\n",
      "         3.00244808e-01,  3.39161307e-01,  6.41378909e-02,\n",
      "        -3.04514170e-01, -5.22534788e-01, -2.76951581e-01,\n",
      "         2.69728601e-01,  1.40680909e-01,  1.33087561e-01],\n",
      "       [ 4.48841959e-01, -4.08090293e-01, -3.38205159e-01,\n",
      "         6.56062365e-02,  1.03098668e-01,  2.64138401e-01,\n",
      "         3.43816876e-01, -2.64138907e-01,  2.18296558e-01,\n",
      "        -1.87904432e-01,  2.23713443e-02,  3.28706861e-01,\n",
      "        -3.46481651e-02,  2.28838399e-01, -2.48576701e-01,\n",
      "        -1.15466686e-02,  2.82429099e-01,  2.36440524e-01],\n",
      "       [-5.98255917e-02, -8.32703635e-02, -2.46096343e-01,\n",
      "         4.33184743e-01,  3.00314873e-01,  1.15980752e-01,\n",
      "        -5.51017880e-01,  5.80974147e-02,  1.39784008e-01,\n",
      "         8.04613531e-02,  2.28975475e-01,  1.35732070e-01,\n",
      "        -1.30421326e-01, -1.13376267e-01,  2.97916085e-01,\n",
      "         3.88301164e-01,  1.85845062e-01,  3.66883218e-01],\n",
      "       [ 8.39004442e-02, -4.08163309e-01,  6.13870323e-02,\n",
      "        -3.94757003e-01, -3.08291584e-01, -2.94849366e-01,\n",
      "         1.29066020e-01, -3.22527140e-01,  2.45547414e-01,\n",
      "         3.56612243e-02, -2.50051022e-01, -1.59718916e-01,\n",
      "        -2.87045509e-01, -2.67733693e-01,  7.17207789e-02,\n",
      "         1.19950391e-01,  2.76820689e-01, -9.27830487e-02],\n",
      "       [-2.38465890e-01, -9.01236609e-02,  1.53497204e-01,\n",
      "         1.32662356e-01, -5.66496812e-02, -1.29340872e-01,\n",
      "         4.19441342e-01,  1.20510392e-01, -1.28274903e-01,\n",
      "         1.72236949e-01,  2.54665285e-01, -4.23879772e-01,\n",
      "        -2.32580990e-01, -2.85837471e-01,  2.06553116e-01,\n",
      "        -5.66668548e-02,  1.79433189e-02,  1.01240344e-01],\n",
      "       [-7.83225987e-03, -3.04189101e-02,  2.06542745e-01,\n",
      "        -2.49971107e-01,  1.85087956e-02,  3.10319990e-01,\n",
      "         3.04563791e-01,  1.75217718e-01, -5.86095117e-02,\n",
      "        -4.04152602e-01,  2.09321633e-01,  7.96289009e-04,\n",
      "         6.09113052e-02,  3.30380052e-01,  2.18508452e-01,\n",
      "         1.93916664e-01, -7.47244656e-02, -3.50490749e-01],\n",
      "       [ 1.61231413e-01, -1.17069427e-02, -2.83399671e-01,\n",
      "         9.55769718e-02, -3.61494035e-01,  4.90887500e-02,\n",
      "         3.08056474e-01, -1.39458358e-01, -8.66273567e-02,\n",
      "        -3.84929962e-02,  1.48858279e-01,  1.23571180e-01,\n",
      "         1.49433196e-01, -3.73895347e-01,  3.53755683e-01,\n",
      "         3.54682326e-01, -1.87107414e-01, -2.10145772e-01],\n",
      "       [ 2.74473190e-01, -2.76080035e-02,  2.37592399e-01,\n",
      "        -3.57239991e-02,  2.25036114e-01,  3.64454351e-02,\n",
      "         9.21206474e-02,  2.50139862e-01, -9.06099230e-02,\n",
      "         8.86170287e-03, -2.76338488e-01, -9.41632167e-02,\n",
      "        -3.40474099e-01,  4.08481449e-01, -3.42121065e-01,\n",
      "        -4.61074822e-02,  1.20247051e-01, -1.46883249e-01],\n",
      "       [ 5.60208261e-02, -3.90785992e-01,  2.61051416e-01,\n",
      "         2.28745252e-01,  1.42888352e-02,  1.20829772e-02,\n",
      "         2.04763964e-01,  1.41523048e-01,  1.18512250e-01,\n",
      "        -8.73970687e-02,  1.23703972e-01,  3.46474275e-02,\n",
      "         1.00996897e-01,  2.21252769e-01,  1.68183148e-02,\n",
      "         2.88569987e-01,  2.66857058e-01,  3.65433812e-01],\n",
      "       [ 3.90262395e-01, -2.99070418e-01,  3.05238426e-01,\n",
      "         4.15375412e-01, -3.34013551e-01, -2.86323726e-01,\n",
      "        -2.87028313e-01,  3.79938376e-03,  1.08291924e-01,\n",
      "        -2.56695509e-01, -1.31602779e-01, -1.59295812e-01,\n",
      "         3.55997145e-01,  9.60118622e-02, -3.22494179e-01,\n",
      "        -2.60315500e-02, -2.47314841e-01, -3.76912318e-02],\n",
      "       [ 4.53237057e-01,  3.59624535e-01, -1.05126485e-01,\n",
      "         1.54085318e-02,  3.68010789e-01,  8.93261433e-02,\n",
      "        -2.27818452e-03,  1.98388457e-01,  5.62527239e-01,\n",
      "         3.35063547e-01, -4.44104046e-01, -3.48711535e-02,\n",
      "         1.47908464e-01,  2.04703197e-01, -7.65146136e-01,\n",
      "         3.92247178e-02, -4.52617079e-01,  1.50005877e-01],\n",
      "       [ 4.77671474e-02, -2.18025923e-01, -7.57615343e-02,\n",
      "         3.28001827e-01, -3.00884596e-03,  1.65605798e-01,\n",
      "        -5.58339238e-01,  2.60586292e-01, -3.28885943e-01,\n",
      "        -5.10505736e-01, -2.88570374e-01, -3.46256763e-01,\n",
      "        -1.91909775e-01, -9.98556167e-02,  6.97518438e-02,\n",
      "        -1.89143226e-01,  5.69162786e-01, -1.02870204e-01]], dtype=float32), array([-0.06334706, -0.04203271, -0.061388  ,  0.04632749, -0.05357866,\n",
      "        0.09817113,  0.11921908, -0.0435376 ,  0.14706665, -0.01108323,\n",
      "       -0.05995828,  0.1604635 ,  0.07947762,  0.01627131, -0.01410071,\n",
      "        0.05102029, -0.01779663, -0.04690701], dtype=float32), array([[ 0.7340601 ,  0.09796537],\n",
      "       [ 0.19050604, -0.8212932 ],\n",
      "       [-0.05655995,  0.24313997],\n",
      "       [-0.3680641 ,  0.11844552],\n",
      "       [-0.39560172,  0.38764715],\n",
      "       [-0.04650882,  0.8572605 ],\n",
      "       [-0.75133336,  0.41227722],\n",
      "       [-0.3238951 , -0.19078936],\n",
      "       [ 0.26774627, -0.6599005 ],\n",
      "       [ 0.16106476, -0.7840901 ],\n",
      "       [ 0.0491427 , -0.5514058 ],\n",
      "       [-0.88896465,  0.6611893 ],\n",
      "       [-0.596689  ,  0.09756182],\n",
      "       [ 0.42673132, -0.9579181 ],\n",
      "       [ 0.7788597 , -1.0195417 ],\n",
      "       [ 0.34215176,  0.5845886 ],\n",
      "       [ 0.52070147, -0.9525411 ],\n",
      "       [-0.77456105,  0.2787379 ]], dtype=float32), array([-0.09456917,  0.09456912], dtype=float32)]\n",
      "<keras.layers.core.dense.Dense object at 0x000001D86E35D1F0> ---------- [array([[ 2.03999087e-01, -1.28053084e-01,  2.51313955e-01,\n",
      "         2.17519537e-01, -3.85622919e-01, -2.66590148e-01,\n",
      "        -6.35308474e-02,  3.64601277e-02, -9.65961143e-02,\n",
      "         3.32777709e-01,  1.93458274e-01,  3.26159805e-01,\n",
      "         9.57212746e-02, -6.75269067e-02,  2.37667665e-01,\n",
      "        -2.67305911e-01,  9.46578905e-02, -1.99721649e-01],\n",
      "       [-9.73574147e-02, -5.87192923e-02, -1.46250157e-02,\n",
      "         3.52003157e-01,  3.36519897e-01, -2.04159990e-01,\n",
      "        -3.80150437e-01,  3.19869280e-01, -8.93107131e-02,\n",
      "        -1.98329724e-02,  2.38479704e-01, -3.18224043e-01,\n",
      "         2.32561097e-01, -1.25210807e-01, -5.98012030e-01,\n",
      "        -4.82303929e-03, -1.40538469e-01,  6.90590218e-02],\n",
      "       [-2.53820360e-01,  1.98137179e-01,  1.41085058e-01,\n",
      "        -1.87789813e-01, -2.18788221e-01, -3.34584951e-01,\n",
      "        -4.86251265e-02, -2.80405760e-01, -3.78104925e-01,\n",
      "        -1.02975234e-01,  2.85323232e-01, -7.44003803e-02,\n",
      "         2.83436447e-01,  2.45306920e-02, -3.17602843e-01,\n",
      "        -1.42352104e-01,  8.36716667e-02,  1.38371587e-01],\n",
      "       [-2.56447345e-01, -4.60955083e-01, -3.77201915e-01,\n",
      "        -7.41861090e-02,  3.23065162e-01, -3.56690705e-01,\n",
      "        -4.58472483e-02, -2.72505730e-01, -7.88209364e-02,\n",
      "        -1.96065769e-01, -1.85968220e-01,  3.28815103e-01,\n",
      "         2.69453317e-01, -3.13699216e-01,  9.43450704e-02,\n",
      "        -2.02118918e-01,  5.86512983e-01, -1.14455022e-01],\n",
      "       [-1.22749992e-01,  2.25588769e-01,  2.50550687e-01,\n",
      "        -3.33043188e-02, -6.56295419e-02,  2.23870516e-01,\n",
      "         2.99711257e-01, -2.96986729e-01, -3.39677036e-01,\n",
      "         2.52314746e-01, -1.22885883e-01,  3.08383673e-01,\n",
      "         2.14228109e-01,  5.52572131e-01,  1.34447506e-02,\n",
      "         2.94843435e-01, -2.40881935e-01, -5.99842966e-01],\n",
      "       [-3.91466431e-02,  3.56668562e-01, -3.23144972e-01,\n",
      "        -3.44871581e-01,  1.06900536e-01,  7.21961632e-02,\n",
      "        -3.67444158e-02, -1.98092386e-01,  3.07729512e-01,\n",
      "         9.85339731e-02, -2.42755517e-01,  1.78677917e-01,\n",
      "         1.75265316e-02, -2.19190702e-01, -1.43023329e-02,\n",
      "         1.48601905e-01, -4.47912276e-01,  1.49233475e-01],\n",
      "       [ 7.11600110e-02, -3.50773990e-01, -8.30872729e-03,\n",
      "        -1.13942102e-01, -4.90959249e-02,  1.27996847e-01,\n",
      "         9.74756628e-02,  2.80071765e-01,  1.63929567e-01,\n",
      "         2.04042077e-01,  9.26570743e-02, -3.28351587e-01,\n",
      "        -2.72852451e-01, -2.10675076e-02, -1.03627376e-01,\n",
      "        -2.62052678e-02, -5.26757650e-02,  3.19823623e-01],\n",
      "       [-2.64720052e-01,  4.50532168e-01,  1.72275305e-01,\n",
      "        -3.38339270e-03,  1.64968088e-01,  1.01350946e-02,\n",
      "        -4.97991405e-02, -6.15504272e-02, -2.17155769e-01,\n",
      "         3.71200852e-02, -7.74002373e-02,  3.58352989e-01,\n",
      "         2.57448763e-01, -4.49516982e-01, -1.26433805e-01,\n",
      "        -2.05262788e-02,  1.19049698e-01, -3.81276041e-01],\n",
      "       [-4.84288932e-04, -2.80432940e-01, -1.34773090e-01,\n",
      "        -1.84680894e-01, -9.78314653e-02, -1.91739276e-01,\n",
      "         6.18840940e-02, -1.71238437e-01, -2.30825365e-01,\n",
      "        -3.84690762e-01, -3.01232696e-01,  2.69586295e-01,\n",
      "         3.16328555e-01,  2.71516919e-01, -1.04377151e-01,\n",
      "        -4.62715216e-02,  3.55194882e-02, -1.50954723e-01],\n",
      "       [-3.67641509e-01, -3.35773006e-02,  2.37671375e-01,\n",
      "        -4.74325791e-02,  9.15693492e-02, -2.62871593e-01,\n",
      "         2.00387701e-01, -2.08246365e-01, -1.08892530e-01,\n",
      "        -5.21442853e-02, -1.63908496e-01, -6.75659776e-01,\n",
      "        -8.86319131e-02,  5.52690625e-02, -3.89595777e-01,\n",
      "        -1.90289229e-01,  9.09255296e-02,  3.85529906e-01],\n",
      "       [ 2.31290162e-01,  1.68200061e-01, -4.07397524e-02,\n",
      "        -2.49302104e-01,  1.33522853e-01,  1.38746366e-01,\n",
      "        -2.49026239e-01,  1.12042733e-01,  4.27619457e-01,\n",
      "        -5.77793121e-02, -1.47379160e-01,  8.52758437e-02,\n",
      "         1.86023396e-02, -2.27688819e-01,  1.96391597e-01,\n",
      "        -3.29662830e-01,  9.39863473e-02, -1.22868605e-01],\n",
      "       [ 2.27850154e-02,  1.38270885e-01, -1.04958169e-01,\n",
      "        -1.40249163e-01,  8.33365694e-02,  2.18973309e-01,\n",
      "         1.42656937e-01, -1.75456211e-01, -3.04457366e-01,\n",
      "         3.86028849e-02,  1.06674604e-01, -1.24057174e-01,\n",
      "         4.43545908e-01, -1.60229132e-01,  2.04711467e-01,\n",
      "        -9.66126248e-02,  1.40200719e-01, -1.69717982e-01],\n",
      "       [-3.25753950e-02, -3.54403228e-01,  2.34008282e-01,\n",
      "        -1.71391964e-01, -1.89611432e-03,  2.57120430e-01,\n",
      "         2.18180612e-01,  1.37032904e-02, -1.31025210e-01,\n",
      "         1.99245796e-01, -2.05733478e-01,  1.77009180e-01,\n",
      "        -7.07801282e-02,  2.87792414e-01, -3.64929408e-01,\n",
      "        -3.29339951e-02, -3.03790092e-01, -7.98829552e-03],\n",
      "       [ 3.50744575e-02, -2.18501166e-01,  2.26974770e-01,\n",
      "         2.71234155e-01, -2.89094895e-01,  2.20593616e-01,\n",
      "        -2.25961301e-02, -3.47777666e-03, -2.40310505e-01,\n",
      "         2.52054143e-03, -2.47311622e-01,  3.36385369e-01,\n",
      "         1.43644493e-02,  4.14453894e-01, -2.22103655e-01,\n",
      "         1.24916933e-01,  4.11539197e-01, -2.69214460e-03],\n",
      "       [ 2.62427270e-01,  3.58384885e-02, -3.10837980e-02,\n",
      "        -4.38702881e-01,  1.27311110e-01, -2.31797218e-01,\n",
      "         7.10984021e-02,  1.84834376e-01, -7.11416006e-02,\n",
      "        -2.49229327e-01, -2.29427025e-01, -1.00606181e-01,\n",
      "        -1.36321872e-01,  1.26960248e-01,  4.61507857e-01,\n",
      "        -2.29719102e-01, -4.77916539e-01, -2.55627424e-01],\n",
      "       [ 1.69170797e-01, -2.67548442e-01,  3.72076988e-01,\n",
      "        -2.48567358e-01,  3.21369171e-01,  4.24694091e-01,\n",
      "         1.31925210e-01,  2.76547018e-02,  2.60763746e-02,\n",
      "         3.00244808e-01,  3.39161307e-01,  6.41378909e-02,\n",
      "        -3.04514170e-01, -5.22534788e-01, -2.76951581e-01,\n",
      "         2.69728601e-01,  1.40680909e-01,  1.33087561e-01],\n",
      "       [ 4.48841959e-01, -4.08090293e-01, -3.38205159e-01,\n",
      "         6.56062365e-02,  1.03098668e-01,  2.64138401e-01,\n",
      "         3.43816876e-01, -2.64138907e-01,  2.18296558e-01,\n",
      "        -1.87904432e-01,  2.23713443e-02,  3.28706861e-01,\n",
      "        -3.46481651e-02,  2.28838399e-01, -2.48576701e-01,\n",
      "        -1.15466686e-02,  2.82429099e-01,  2.36440524e-01],\n",
      "       [-5.98255917e-02, -8.32703635e-02, -2.46096343e-01,\n",
      "         4.33184743e-01,  3.00314873e-01,  1.15980752e-01,\n",
      "        -5.51017880e-01,  5.80974147e-02,  1.39784008e-01,\n",
      "         8.04613531e-02,  2.28975475e-01,  1.35732070e-01,\n",
      "        -1.30421326e-01, -1.13376267e-01,  2.97916085e-01,\n",
      "         3.88301164e-01,  1.85845062e-01,  3.66883218e-01],\n",
      "       [ 8.39004442e-02, -4.08163309e-01,  6.13870323e-02,\n",
      "        -3.94757003e-01, -3.08291584e-01, -2.94849366e-01,\n",
      "         1.29066020e-01, -3.22527140e-01,  2.45547414e-01,\n",
      "         3.56612243e-02, -2.50051022e-01, -1.59718916e-01,\n",
      "        -2.87045509e-01, -2.67733693e-01,  7.17207789e-02,\n",
      "         1.19950391e-01,  2.76820689e-01, -9.27830487e-02],\n",
      "       [-2.38465890e-01, -9.01236609e-02,  1.53497204e-01,\n",
      "         1.32662356e-01, -5.66496812e-02, -1.29340872e-01,\n",
      "         4.19441342e-01,  1.20510392e-01, -1.28274903e-01,\n",
      "         1.72236949e-01,  2.54665285e-01, -4.23879772e-01,\n",
      "        -2.32580990e-01, -2.85837471e-01,  2.06553116e-01,\n",
      "        -5.66668548e-02,  1.79433189e-02,  1.01240344e-01],\n",
      "       [-7.83225987e-03, -3.04189101e-02,  2.06542745e-01,\n",
      "        -2.49971107e-01,  1.85087956e-02,  3.10319990e-01,\n",
      "         3.04563791e-01,  1.75217718e-01, -5.86095117e-02,\n",
      "        -4.04152602e-01,  2.09321633e-01,  7.96289009e-04,\n",
      "         6.09113052e-02,  3.30380052e-01,  2.18508452e-01,\n",
      "         1.93916664e-01, -7.47244656e-02, -3.50490749e-01],\n",
      "       [ 1.61231413e-01, -1.17069427e-02, -2.83399671e-01,\n",
      "         9.55769718e-02, -3.61494035e-01,  4.90887500e-02,\n",
      "         3.08056474e-01, -1.39458358e-01, -8.66273567e-02,\n",
      "        -3.84929962e-02,  1.48858279e-01,  1.23571180e-01,\n",
      "         1.49433196e-01, -3.73895347e-01,  3.53755683e-01,\n",
      "         3.54682326e-01, -1.87107414e-01, -2.10145772e-01],\n",
      "       [ 2.74473190e-01, -2.76080035e-02,  2.37592399e-01,\n",
      "        -3.57239991e-02,  2.25036114e-01,  3.64454351e-02,\n",
      "         9.21206474e-02,  2.50139862e-01, -9.06099230e-02,\n",
      "         8.86170287e-03, -2.76338488e-01, -9.41632167e-02,\n",
      "        -3.40474099e-01,  4.08481449e-01, -3.42121065e-01,\n",
      "        -4.61074822e-02,  1.20247051e-01, -1.46883249e-01],\n",
      "       [ 5.60208261e-02, -3.90785992e-01,  2.61051416e-01,\n",
      "         2.28745252e-01,  1.42888352e-02,  1.20829772e-02,\n",
      "         2.04763964e-01,  1.41523048e-01,  1.18512250e-01,\n",
      "        -8.73970687e-02,  1.23703972e-01,  3.46474275e-02,\n",
      "         1.00996897e-01,  2.21252769e-01,  1.68183148e-02,\n",
      "         2.88569987e-01,  2.66857058e-01,  3.65433812e-01],\n",
      "       [ 3.90262395e-01, -2.99070418e-01,  3.05238426e-01,\n",
      "         4.15375412e-01, -3.34013551e-01, -2.86323726e-01,\n",
      "        -2.87028313e-01,  3.79938376e-03,  1.08291924e-01,\n",
      "        -2.56695509e-01, -1.31602779e-01, -1.59295812e-01,\n",
      "         3.55997145e-01,  9.60118622e-02, -3.22494179e-01,\n",
      "        -2.60315500e-02, -2.47314841e-01, -3.76912318e-02],\n",
      "       [ 4.53237057e-01,  3.59624535e-01, -1.05126485e-01,\n",
      "         1.54085318e-02,  3.68010789e-01,  8.93261433e-02,\n",
      "        -2.27818452e-03,  1.98388457e-01,  5.62527239e-01,\n",
      "         3.35063547e-01, -4.44104046e-01, -3.48711535e-02,\n",
      "         1.47908464e-01,  2.04703197e-01, -7.65146136e-01,\n",
      "         3.92247178e-02, -4.52617079e-01,  1.50005877e-01],\n",
      "       [ 4.77671474e-02, -2.18025923e-01, -7.57615343e-02,\n",
      "         3.28001827e-01, -3.00884596e-03,  1.65605798e-01,\n",
      "        -5.58339238e-01,  2.60586292e-01, -3.28885943e-01,\n",
      "        -5.10505736e-01, -2.88570374e-01, -3.46256763e-01,\n",
      "        -1.91909775e-01, -9.98556167e-02,  6.97518438e-02,\n",
      "        -1.89143226e-01,  5.69162786e-01, -1.02870204e-01]], dtype=float32), array([-0.06334706, -0.04203271, -0.061388  ,  0.04632749, -0.05357866,\n",
      "        0.09817113,  0.11921908, -0.0435376 ,  0.14706665, -0.01108323,\n",
      "       -0.05995828,  0.1604635 ,  0.07947762,  0.01627131, -0.01410071,\n",
      "        0.05102029, -0.01779663, -0.04690701], dtype=float32), array([[ 0.7340601 ,  0.09796537],\n",
      "       [ 0.19050604, -0.8212932 ],\n",
      "       [-0.05655995,  0.24313997],\n",
      "       [-0.3680641 ,  0.11844552],\n",
      "       [-0.39560172,  0.38764715],\n",
      "       [-0.04650882,  0.8572605 ],\n",
      "       [-0.75133336,  0.41227722],\n",
      "       [-0.3238951 , -0.19078936],\n",
      "       [ 0.26774627, -0.6599005 ],\n",
      "       [ 0.16106476, -0.7840901 ],\n",
      "       [ 0.0491427 , -0.5514058 ],\n",
      "       [-0.88896465,  0.6611893 ],\n",
      "       [-0.596689  ,  0.09756182],\n",
      "       [ 0.42673132, -0.9579181 ],\n",
      "       [ 0.7788597 , -1.0195417 ],\n",
      "       [ 0.34215176,  0.5845886 ],\n",
      "       [ 0.52070147, -0.9525411 ],\n",
      "       [-0.77456105,  0.2787379 ]], dtype=float32), array([-0.09456917,  0.09456912], dtype=float32)]\n",
      "<keras.layers.core.dense.Dense object at 0x000001D86E35D670> ---------- [array([[ 2.03999087e-01, -1.28053084e-01,  2.51313955e-01,\n",
      "         2.17519537e-01, -3.85622919e-01, -2.66590148e-01,\n",
      "        -6.35308474e-02,  3.64601277e-02, -9.65961143e-02,\n",
      "         3.32777709e-01,  1.93458274e-01,  3.26159805e-01,\n",
      "         9.57212746e-02, -6.75269067e-02,  2.37667665e-01,\n",
      "        -2.67305911e-01,  9.46578905e-02, -1.99721649e-01],\n",
      "       [-9.73574147e-02, -5.87192923e-02, -1.46250157e-02,\n",
      "         3.52003157e-01,  3.36519897e-01, -2.04159990e-01,\n",
      "        -3.80150437e-01,  3.19869280e-01, -8.93107131e-02,\n",
      "        -1.98329724e-02,  2.38479704e-01, -3.18224043e-01,\n",
      "         2.32561097e-01, -1.25210807e-01, -5.98012030e-01,\n",
      "        -4.82303929e-03, -1.40538469e-01,  6.90590218e-02],\n",
      "       [-2.53820360e-01,  1.98137179e-01,  1.41085058e-01,\n",
      "        -1.87789813e-01, -2.18788221e-01, -3.34584951e-01,\n",
      "        -4.86251265e-02, -2.80405760e-01, -3.78104925e-01,\n",
      "        -1.02975234e-01,  2.85323232e-01, -7.44003803e-02,\n",
      "         2.83436447e-01,  2.45306920e-02, -3.17602843e-01,\n",
      "        -1.42352104e-01,  8.36716667e-02,  1.38371587e-01],\n",
      "       [-2.56447345e-01, -4.60955083e-01, -3.77201915e-01,\n",
      "        -7.41861090e-02,  3.23065162e-01, -3.56690705e-01,\n",
      "        -4.58472483e-02, -2.72505730e-01, -7.88209364e-02,\n",
      "        -1.96065769e-01, -1.85968220e-01,  3.28815103e-01,\n",
      "         2.69453317e-01, -3.13699216e-01,  9.43450704e-02,\n",
      "        -2.02118918e-01,  5.86512983e-01, -1.14455022e-01],\n",
      "       [-1.22749992e-01,  2.25588769e-01,  2.50550687e-01,\n",
      "        -3.33043188e-02, -6.56295419e-02,  2.23870516e-01,\n",
      "         2.99711257e-01, -2.96986729e-01, -3.39677036e-01,\n",
      "         2.52314746e-01, -1.22885883e-01,  3.08383673e-01,\n",
      "         2.14228109e-01,  5.52572131e-01,  1.34447506e-02,\n",
      "         2.94843435e-01, -2.40881935e-01, -5.99842966e-01],\n",
      "       [-3.91466431e-02,  3.56668562e-01, -3.23144972e-01,\n",
      "        -3.44871581e-01,  1.06900536e-01,  7.21961632e-02,\n",
      "        -3.67444158e-02, -1.98092386e-01,  3.07729512e-01,\n",
      "         9.85339731e-02, -2.42755517e-01,  1.78677917e-01,\n",
      "         1.75265316e-02, -2.19190702e-01, -1.43023329e-02,\n",
      "         1.48601905e-01, -4.47912276e-01,  1.49233475e-01],\n",
      "       [ 7.11600110e-02, -3.50773990e-01, -8.30872729e-03,\n",
      "        -1.13942102e-01, -4.90959249e-02,  1.27996847e-01,\n",
      "         9.74756628e-02,  2.80071765e-01,  1.63929567e-01,\n",
      "         2.04042077e-01,  9.26570743e-02, -3.28351587e-01,\n",
      "        -2.72852451e-01, -2.10675076e-02, -1.03627376e-01,\n",
      "        -2.62052678e-02, -5.26757650e-02,  3.19823623e-01],\n",
      "       [-2.64720052e-01,  4.50532168e-01,  1.72275305e-01,\n",
      "        -3.38339270e-03,  1.64968088e-01,  1.01350946e-02,\n",
      "        -4.97991405e-02, -6.15504272e-02, -2.17155769e-01,\n",
      "         3.71200852e-02, -7.74002373e-02,  3.58352989e-01,\n",
      "         2.57448763e-01, -4.49516982e-01, -1.26433805e-01,\n",
      "        -2.05262788e-02,  1.19049698e-01, -3.81276041e-01],\n",
      "       [-4.84288932e-04, -2.80432940e-01, -1.34773090e-01,\n",
      "        -1.84680894e-01, -9.78314653e-02, -1.91739276e-01,\n",
      "         6.18840940e-02, -1.71238437e-01, -2.30825365e-01,\n",
      "        -3.84690762e-01, -3.01232696e-01,  2.69586295e-01,\n",
      "         3.16328555e-01,  2.71516919e-01, -1.04377151e-01,\n",
      "        -4.62715216e-02,  3.55194882e-02, -1.50954723e-01],\n",
      "       [-3.67641509e-01, -3.35773006e-02,  2.37671375e-01,\n",
      "        -4.74325791e-02,  9.15693492e-02, -2.62871593e-01,\n",
      "         2.00387701e-01, -2.08246365e-01, -1.08892530e-01,\n",
      "        -5.21442853e-02, -1.63908496e-01, -6.75659776e-01,\n",
      "        -8.86319131e-02,  5.52690625e-02, -3.89595777e-01,\n",
      "        -1.90289229e-01,  9.09255296e-02,  3.85529906e-01],\n",
      "       [ 2.31290162e-01,  1.68200061e-01, -4.07397524e-02,\n",
      "        -2.49302104e-01,  1.33522853e-01,  1.38746366e-01,\n",
      "        -2.49026239e-01,  1.12042733e-01,  4.27619457e-01,\n",
      "        -5.77793121e-02, -1.47379160e-01,  8.52758437e-02,\n",
      "         1.86023396e-02, -2.27688819e-01,  1.96391597e-01,\n",
      "        -3.29662830e-01,  9.39863473e-02, -1.22868605e-01],\n",
      "       [ 2.27850154e-02,  1.38270885e-01, -1.04958169e-01,\n",
      "        -1.40249163e-01,  8.33365694e-02,  2.18973309e-01,\n",
      "         1.42656937e-01, -1.75456211e-01, -3.04457366e-01,\n",
      "         3.86028849e-02,  1.06674604e-01, -1.24057174e-01,\n",
      "         4.43545908e-01, -1.60229132e-01,  2.04711467e-01,\n",
      "        -9.66126248e-02,  1.40200719e-01, -1.69717982e-01],\n",
      "       [-3.25753950e-02, -3.54403228e-01,  2.34008282e-01,\n",
      "        -1.71391964e-01, -1.89611432e-03,  2.57120430e-01,\n",
      "         2.18180612e-01,  1.37032904e-02, -1.31025210e-01,\n",
      "         1.99245796e-01, -2.05733478e-01,  1.77009180e-01,\n",
      "        -7.07801282e-02,  2.87792414e-01, -3.64929408e-01,\n",
      "        -3.29339951e-02, -3.03790092e-01, -7.98829552e-03],\n",
      "       [ 3.50744575e-02, -2.18501166e-01,  2.26974770e-01,\n",
      "         2.71234155e-01, -2.89094895e-01,  2.20593616e-01,\n",
      "        -2.25961301e-02, -3.47777666e-03, -2.40310505e-01,\n",
      "         2.52054143e-03, -2.47311622e-01,  3.36385369e-01,\n",
      "         1.43644493e-02,  4.14453894e-01, -2.22103655e-01,\n",
      "         1.24916933e-01,  4.11539197e-01, -2.69214460e-03],\n",
      "       [ 2.62427270e-01,  3.58384885e-02, -3.10837980e-02,\n",
      "        -4.38702881e-01,  1.27311110e-01, -2.31797218e-01,\n",
      "         7.10984021e-02,  1.84834376e-01, -7.11416006e-02,\n",
      "        -2.49229327e-01, -2.29427025e-01, -1.00606181e-01,\n",
      "        -1.36321872e-01,  1.26960248e-01,  4.61507857e-01,\n",
      "        -2.29719102e-01, -4.77916539e-01, -2.55627424e-01],\n",
      "       [ 1.69170797e-01, -2.67548442e-01,  3.72076988e-01,\n",
      "        -2.48567358e-01,  3.21369171e-01,  4.24694091e-01,\n",
      "         1.31925210e-01,  2.76547018e-02,  2.60763746e-02,\n",
      "         3.00244808e-01,  3.39161307e-01,  6.41378909e-02,\n",
      "        -3.04514170e-01, -5.22534788e-01, -2.76951581e-01,\n",
      "         2.69728601e-01,  1.40680909e-01,  1.33087561e-01],\n",
      "       [ 4.48841959e-01, -4.08090293e-01, -3.38205159e-01,\n",
      "         6.56062365e-02,  1.03098668e-01,  2.64138401e-01,\n",
      "         3.43816876e-01, -2.64138907e-01,  2.18296558e-01,\n",
      "        -1.87904432e-01,  2.23713443e-02,  3.28706861e-01,\n",
      "        -3.46481651e-02,  2.28838399e-01, -2.48576701e-01,\n",
      "        -1.15466686e-02,  2.82429099e-01,  2.36440524e-01],\n",
      "       [-5.98255917e-02, -8.32703635e-02, -2.46096343e-01,\n",
      "         4.33184743e-01,  3.00314873e-01,  1.15980752e-01,\n",
      "        -5.51017880e-01,  5.80974147e-02,  1.39784008e-01,\n",
      "         8.04613531e-02,  2.28975475e-01,  1.35732070e-01,\n",
      "        -1.30421326e-01, -1.13376267e-01,  2.97916085e-01,\n",
      "         3.88301164e-01,  1.85845062e-01,  3.66883218e-01],\n",
      "       [ 8.39004442e-02, -4.08163309e-01,  6.13870323e-02,\n",
      "        -3.94757003e-01, -3.08291584e-01, -2.94849366e-01,\n",
      "         1.29066020e-01, -3.22527140e-01,  2.45547414e-01,\n",
      "         3.56612243e-02, -2.50051022e-01, -1.59718916e-01,\n",
      "        -2.87045509e-01, -2.67733693e-01,  7.17207789e-02,\n",
      "         1.19950391e-01,  2.76820689e-01, -9.27830487e-02],\n",
      "       [-2.38465890e-01, -9.01236609e-02,  1.53497204e-01,\n",
      "         1.32662356e-01, -5.66496812e-02, -1.29340872e-01,\n",
      "         4.19441342e-01,  1.20510392e-01, -1.28274903e-01,\n",
      "         1.72236949e-01,  2.54665285e-01, -4.23879772e-01,\n",
      "        -2.32580990e-01, -2.85837471e-01,  2.06553116e-01,\n",
      "        -5.66668548e-02,  1.79433189e-02,  1.01240344e-01],\n",
      "       [-7.83225987e-03, -3.04189101e-02,  2.06542745e-01,\n",
      "        -2.49971107e-01,  1.85087956e-02,  3.10319990e-01,\n",
      "         3.04563791e-01,  1.75217718e-01, -5.86095117e-02,\n",
      "        -4.04152602e-01,  2.09321633e-01,  7.96289009e-04,\n",
      "         6.09113052e-02,  3.30380052e-01,  2.18508452e-01,\n",
      "         1.93916664e-01, -7.47244656e-02, -3.50490749e-01],\n",
      "       [ 1.61231413e-01, -1.17069427e-02, -2.83399671e-01,\n",
      "         9.55769718e-02, -3.61494035e-01,  4.90887500e-02,\n",
      "         3.08056474e-01, -1.39458358e-01, -8.66273567e-02,\n",
      "        -3.84929962e-02,  1.48858279e-01,  1.23571180e-01,\n",
      "         1.49433196e-01, -3.73895347e-01,  3.53755683e-01,\n",
      "         3.54682326e-01, -1.87107414e-01, -2.10145772e-01],\n",
      "       [ 2.74473190e-01, -2.76080035e-02,  2.37592399e-01,\n",
      "        -3.57239991e-02,  2.25036114e-01,  3.64454351e-02,\n",
      "         9.21206474e-02,  2.50139862e-01, -9.06099230e-02,\n",
      "         8.86170287e-03, -2.76338488e-01, -9.41632167e-02,\n",
      "        -3.40474099e-01,  4.08481449e-01, -3.42121065e-01,\n",
      "        -4.61074822e-02,  1.20247051e-01, -1.46883249e-01],\n",
      "       [ 5.60208261e-02, -3.90785992e-01,  2.61051416e-01,\n",
      "         2.28745252e-01,  1.42888352e-02,  1.20829772e-02,\n",
      "         2.04763964e-01,  1.41523048e-01,  1.18512250e-01,\n",
      "        -8.73970687e-02,  1.23703972e-01,  3.46474275e-02,\n",
      "         1.00996897e-01,  2.21252769e-01,  1.68183148e-02,\n",
      "         2.88569987e-01,  2.66857058e-01,  3.65433812e-01],\n",
      "       [ 3.90262395e-01, -2.99070418e-01,  3.05238426e-01,\n",
      "         4.15375412e-01, -3.34013551e-01, -2.86323726e-01,\n",
      "        -2.87028313e-01,  3.79938376e-03,  1.08291924e-01,\n",
      "        -2.56695509e-01, -1.31602779e-01, -1.59295812e-01,\n",
      "         3.55997145e-01,  9.60118622e-02, -3.22494179e-01,\n",
      "        -2.60315500e-02, -2.47314841e-01, -3.76912318e-02],\n",
      "       [ 4.53237057e-01,  3.59624535e-01, -1.05126485e-01,\n",
      "         1.54085318e-02,  3.68010789e-01,  8.93261433e-02,\n",
      "        -2.27818452e-03,  1.98388457e-01,  5.62527239e-01,\n",
      "         3.35063547e-01, -4.44104046e-01, -3.48711535e-02,\n",
      "         1.47908464e-01,  2.04703197e-01, -7.65146136e-01,\n",
      "         3.92247178e-02, -4.52617079e-01,  1.50005877e-01],\n",
      "       [ 4.77671474e-02, -2.18025923e-01, -7.57615343e-02,\n",
      "         3.28001827e-01, -3.00884596e-03,  1.65605798e-01,\n",
      "        -5.58339238e-01,  2.60586292e-01, -3.28885943e-01,\n",
      "        -5.10505736e-01, -2.88570374e-01, -3.46256763e-01,\n",
      "        -1.91909775e-01, -9.98556167e-02,  6.97518438e-02,\n",
      "        -1.89143226e-01,  5.69162786e-01, -1.02870204e-01]], dtype=float32), array([-0.06334706, -0.04203271, -0.061388  ,  0.04632749, -0.05357866,\n",
      "        0.09817113,  0.11921908, -0.0435376 ,  0.14706665, -0.01108323,\n",
      "       -0.05995828,  0.1604635 ,  0.07947762,  0.01627131, -0.01410071,\n",
      "        0.05102029, -0.01779663, -0.04690701], dtype=float32), array([[ 0.7340601 ,  0.09796537],\n",
      "       [ 0.19050604, -0.8212932 ],\n",
      "       [-0.05655995,  0.24313997],\n",
      "       [-0.3680641 ,  0.11844552],\n",
      "       [-0.39560172,  0.38764715],\n",
      "       [-0.04650882,  0.8572605 ],\n",
      "       [-0.75133336,  0.41227722],\n",
      "       [-0.3238951 , -0.19078936],\n",
      "       [ 0.26774627, -0.6599005 ],\n",
      "       [ 0.16106476, -0.7840901 ],\n",
      "       [ 0.0491427 , -0.5514058 ],\n",
      "       [-0.88896465,  0.6611893 ],\n",
      "       [-0.596689  ,  0.09756182],\n",
      "       [ 0.42673132, -0.9579181 ],\n",
      "       [ 0.7788597 , -1.0195417 ],\n",
      "       [ 0.34215176,  0.5845886 ],\n",
      "       [ 0.52070147, -0.9525411 ],\n",
      "       [-0.77456105,  0.2787379 ]], dtype=float32), array([-0.09456917,  0.09456912], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "names = [weight.name for layer in nn.layers for weight in nn.weights]\n",
    "weights = nn.get_weights()\n",
    "\n",
    "for name, weight in zip(names, weights):\n",
    "    print(name, weight.shape)\n",
    "for layer in nn.layers:\n",
    "    print(layer,\"----------\",nn.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfe66de",
   "metadata": {},
   "source": [
    "CounterfactualProto parameters: <br>\n",
    "\n",
    "* shape: shape of the instance to be explained<br>\n",
    "* beta: loss term multiplier. A higher value means more weight on the sparsity restrictions of the perturbations.<br>\n",
    "* theta: multiplier for the last loss term. A higher value means more emphasis on the gradients guiding the counterfactual towards the nearest class prototype. <br>\n",
    "* c_init and c_steps: the multiplier of the first loss term is updated for *c_steps* iterations, starting at *c_init*<br>\n",
    "\n",
    "d_type refers to the distance metric used to convert the categorical to numerical values. <br>\n",
    "Option values: abdm, mvdm and abdm-mvdm. <br>\n",
    "1. abdm: uses context provided by the other variables.<br>\n",
    "2. mvdm: using the model predictions<br>\n",
    "3. abdm-mvdm: combines both methods.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dfa1bdea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(matrix([[ 0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "          -1.4545335, -1.0703293, -1.4017133,  0.       ]], dtype=float32),\n",
       " matrix([[1.       , 1.       , 1.       , 1.       , 1.       ,\n",
       "          3.4683406, 5.368103 , 4.237315 , 1.       ]], dtype=float32))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = x_test[1].shape\n",
    "a=(np.ones((1,5)) * 0)\n",
    "b=(np.ones((1,5)) * 1)\n",
    "c = np.min(df_clean[:,-4:], axis=0)\n",
    "d = np.max(df_clean[:,-4:], axis=0)\n",
    "min_feature = np.concatenate((a, c), axis=1)\n",
    "max_feature = np.concatenate((b, d), axis=1)\n",
    "feature_range = (min_feature.astype(np.float32),\n",
    "                 max_feature.astype(np.float32))\n",
    "feature_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd255aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    }
   ],
   "source": [
    "cf = CounterfactualProto(nn,\n",
    "                         shape,\n",
    "                         beta=0.01,\n",
    "                         theta = 100,\n",
    "                         cat_vars=cat_vars_ohe,\n",
    "                         ohe=True,\n",
    "                         max_iterations=500,\n",
    "                         feature_range=feature_range,\n",
    "                         c_init=1,\n",
    "                         c_steps=5\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a69c79d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf.fit(x_train, d_type='mvdm');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5fcb315f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5721996, 0.3574605]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.predict(x_test[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "12795b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09084836, 0.8194923 ]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.predict(x_test[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f4eab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = x_test[7].reshape((1,) + x_test[7].shape)\n",
    "explanation0 = cf.explain(x0)\n",
    "x1 = x_test[4].reshape((1,) + x_test[4].shape)\n",
    "explanation1 = cf.explain(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "88dab565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Explanation(meta={\n",
       "  'name': 'CounterfactualProto',\n",
       "  'type': ['blackbox', 'tensorflow', 'keras'],\n",
       "  'explanations': ['local'],\n",
       "  'params': {\n",
       "              'kappa': 0.0,\n",
       "              'beta': 0.01,\n",
       "              'feature_range': (matrix([[ 0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         -1.4545335, -1.0703293, -1.4017133,  0.       ]], dtype=float32), matrix([[1.       , 1.       , 1.       , 1.       , 1.       ,\n",
       "         3.4683406, 5.368103 , 4.237315 , 1.       ]], dtype=float32)),\n",
       "              'gamma': 0.0,\n",
       "              'theta': 100,\n",
       "              'cat_vars': {0: 2, 2: 4, 6: 3, 9: 4, 13: 3, 16: 8},\n",
       "              'ohe': True,\n",
       "              'use_kdtree': False,\n",
       "              'learning_rate_init': 0.01,\n",
       "              'max_iterations': 500,\n",
       "              'c_init': 1,\n",
       "              'c_steps': 5,\n",
       "              'eps': (0.001, 0.001),\n",
       "              'clip': (-1000.0, 1000.0),\n",
       "              'update_num_grad': 1,\n",
       "              'write_dir': None,\n",
       "              'shape': (1, 27),\n",
       "              'is_model': True,\n",
       "              'is_ae': False,\n",
       "              'is_enc': False,\n",
       "              'enc_or_kdtree': False,\n",
       "              'is_cat': True,\n",
       "              'trustscore_kwargs': None,\n",
       "              'd_type': 'mvdm',\n",
       "              'w': None,\n",
       "              'disc_perc': (25, 50, 75),\n",
       "              'standardize_cat_vars': False,\n",
       "              'smooth': 1.0,\n",
       "              'center': True,\n",
       "              'update_feature_range': True}\n",
       "            ,\n",
       "  'version': '0.6.5'}\n",
       ", data={\n",
       "  'cf': {\n",
       "          'X': array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.237622  ,\n",
       "        -0.07500914, -0.02464949]], dtype=float32),\n",
       "          'class': 0,\n",
       "          'proba': array([[0.4960399 , 0.46273115]], dtype=float32),\n",
       "          'grads_graph': array([[ 1.1257637 ,  1.6054738 ,  1.9430554 , -0.4716323 ,  0.5687716 ,\n",
       "         1.1467052 , -0.49455708, -1.0407579 ,  1.4967175 ]],\n",
       "      dtype=float32),\n",
       "          'grads_num': array([[0., 0., 0., 0., 0., 0., 0., 0., 0.]])}\n",
       "        ,\n",
       "  'all': {\n",
       "           0: [],\n",
       "           1: [array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.2649312 ,\n",
       "         0.35289875, -0.02432705]], dtype=float32), array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.237622  ,\n",
       "         0.3290567 , -0.02207417]], dtype=float32), array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.237622  ,\n",
       "         0.31773797, -0.02205048]], dtype=float32), array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.237622  ,\n",
       "         0.30680057, -0.02202654]], dtype=float32), array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.237622  ,\n",
       "         0.29622877, -0.0220024 ]], dtype=float32), array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.237622  ,\n",
       "         0.28600755, -0.02197806]], dtype=float32), array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.237622  ,\n",
       "         0.27612248, -0.02195353]], dtype=float32), array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.237622  ,\n",
       "         0.26655975, -0.02192882]], dtype=float32), array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.237622  ,\n",
       "         0.25730616, -0.02190393]], dtype=float32), array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.237622  ,\n",
       "         0.24834906, -0.02187886]], dtype=float32), array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.237622  ,\n",
       "         0.23967636, -0.02185362]], dtype=float32), array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.237622  ,\n",
       "         0.23127647, -0.02182821]], dtype=float32), array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.237622  ,\n",
       "         0.22313829, -0.02180263]], dtype=float32), array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.237622  ,\n",
       "         0.21525116, -0.0217769 ]], dtype=float32), array([[ 0.       ,  1.       ,  0.       ,  0.       ,  0.       ,\n",
       "         1.       ,  1.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  1.       ,  1.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         1.       ,  0.       ,  0.       ,  0.       ,  2.237622 ,\n",
       "         0.2076049, -0.021751 ]], dtype=float32), array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.2376876 ,\n",
       "         0.02914221, -0.02064215]], dtype=float32), array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.237739  ,\n",
       "         0.03844629, -0.02353223]], dtype=float32), array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.2377768 ,\n",
       "         0.0475608 , -0.02351498]], dtype=float32), array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.237622  ,\n",
       "         0.0476006 , -0.02342895]], dtype=float32), array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.237622  ,\n",
       "         0.04731873, -0.02334237]], dtype=float32), array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.237622  ,\n",
       "         0.04674016, -0.02325523]], dtype=float32), array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.237622  ,\n",
       "         0.04588724, -0.02316751]], dtype=float32), array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.237622  ,\n",
       "         0.04477993, -0.02307921]], dtype=float32), array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.237622  ,\n",
       "         0.04343604, -0.02299031]], dtype=float32), array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.237622  ,\n",
       "         0.04187144, -0.0229008 ]], dtype=float32), array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.237622  ,\n",
       "         0.04010022, -0.02281066]], dtype=float32), array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.237622  ,\n",
       "         0.03813494, -0.02271989]], dtype=float32)],\n",
       "           2: [array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.237622  ,\n",
       "        -0.07226995, -0.02483759]], dtype=float32), array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.237622  ,\n",
       "        -0.06941463, -0.02482237]], dtype=float32)],\n",
       "           3: [],\n",
       "           4: [array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  2.237622  ,\n",
       "        -0.07500914, -0.02464949]], dtype=float32)]}\n",
       "         ,\n",
       "  'orig_class': 1,\n",
       "  'orig_proba': array([[0.09084836, 0.8194923 ]], dtype=float32),\n",
       "  'id_proto': None}\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55b397dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prediction of x0: 0\n",
      "Counterfactual prediction of x0: 1\n",
      "Original prediction of x1: 1\n",
      "Counterfactual prediction of x1: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'Original prediction of x0: {explanation0.orig_class}')\n",
    "print('Counterfactual prediction of x0: {}'.format(explanation0.cf['class']))\n",
    "print(f'Original prediction of x1: {explanation1.orig_class}')\n",
    "print('Counterfactual prediction of x1: {}'.format(explanation1.cf['class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "403cd10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_instance(x, explanation, eps=1):\n",
    "    target_names = ['Good', 'Bad']\n",
    "    feature_names = ['Sex', 'Job', 'Housing', 'Saving accounts', 'Checking account','Purpose', 'Age', 'Credit amount', 'Duration']\n",
    "    print('Original instance: {}  -- probability: {}'.format(target_names[explanation.orig_class],\n",
    "                                                       explanation.orig_proba[0]))\n",
    "    print('Counterfactual instance: {}  -- probability: {}'.format(target_names[explanation.cf['class']],\n",
    "                                                             explanation.cf['proba'][0]))\n",
    "    category_map = {}\n",
    "    i=0;\n",
    "    for col in df.iloc[:,:-1].columns.to_list():\n",
    "            if(i==1):\n",
    "                category_map[i] = ['0','1','2','3'] #for job\n",
    "                i=i+1\n",
    "            if(df[col].dtype == \"object\"):\n",
    "                category_map[i] = df[col].unique().tolist()\n",
    "                i=i+1\n",
    "    \n",
    "    X = np.c_[df_new.iloc[:,1:6], df_new.iloc[:,8:9], df_new.iloc[:,0:1], df_new.iloc[:,6:8]]\n",
    "    cat_vars_ord = {}\n",
    "    n_categories = len(list(category_map.keys()))\n",
    "    for i in range(n_categories):\n",
    "        cat_vars_ord[i] = len(np.unique(X[:, i]))\n",
    "\n",
    "    print('\\nCounterfactual perturbations...')\n",
    "    print('\\nCategorical:')\n",
    "    X_orig_ord = ohe_to_ord(x, cat_vars_ohe)[0]\n",
    "    X_cf_ord = ohe_to_ord(explanation.cf['X'], cat_vars_ohe)[0]\n",
    "    delta_cat = {}\n",
    "    for i, (_, v) in enumerate(category_map.items()):\n",
    "        cat_orig = v[int(X_orig_ord[0, i])]\n",
    "        cat_cf = v[int(X_cf_ord[0, i])]\n",
    "        if cat_orig != cat_cf:\n",
    "            delta_cat[feature_names[i]] = [cat_orig, cat_cf]\n",
    "    if delta_cat:\n",
    "        for k, v in delta_cat.items():\n",
    "            print('{}: {}  -->   {}'.format(k, v[0], v[1]))\n",
    "    print('\\nNumerical:')\n",
    "    X_orig_ord = np.asmatrix(pd.DataFrame(x[:,-3:],columns=['Age', 'Credit amount', 'Duration'])* sigma + mu)\n",
    "    X_cf_ord = np.asmatrix(pd.DataFrame(explanation.cf['X'][:,-3:],columns=['Age', 'Credit amount', 'Duration'])* sigma + mu)\n",
    "    delta_num = (X_cf_ord) - (X_orig_ord)\n",
    "    n_keys = len(list(cat_vars_ord.keys()))\n",
    "    for i in range(delta_num.shape[1]):\n",
    "        if np.abs(delta_num[0, i]) > eps:\n",
    "            print('{}: {:.2f}  -->   {:.2f}'.format(feature_names[i+n_keys],\n",
    "                                            X_orig_ord[0,i],\n",
    "                                            X_cf_ord[0,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1ddc7b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original instance: Good  -- probability: [0.5721996 0.3574605]\n",
      "Counterfactual instance: Bad  -- probability: [0.38731623 0.39596432]\n",
      "\n",
      "Counterfactual perturbations...\n",
      "\n",
      "Categorical:\n",
      "Job: 1  -->   2\n",
      "Checking account: moderate  -->   little\n",
      "Purpose: radio/TV  -->   education\n",
      "\n",
      "Numerical:\n",
      "Credit amount: 5954.00  -->   6086.09\n",
      "Duration: 42.00  -->   40.88\n"
     ]
    }
   ],
   "source": [
    "describe_instance(x0, explanation0)\n",
    "#  job values: 0 - unskilled and non-resident, 1 - unskilled and resident, 2 - skilled, 3 - highly skilled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6c773a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original instance: Bad  -- probability: [0.09084836 0.8194923 ]\n",
      "Counterfactual instance: Good  -- probability: [0.4960399  0.46273115]\n",
      "\n",
      "Counterfactual perturbations...\n",
      "\n",
      "Categorical:\n",
      "Job: 1  -->   3\n",
      "Housing: free  -->   own\n",
      "Purpose: domestic appliances  -->   business\n",
      "\n",
      "Numerical:\n",
      "Duration: 12.00  -->   20.61\n"
     ]
    }
   ],
   "source": [
    "describe_instance(x1, explanation1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bdc566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
